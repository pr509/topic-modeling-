{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic modeling .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqOQJrXK-5E"
      },
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim import models\n",
        "from gensim.utils import simple_preprocess,lemmatize\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel,LdaMulticore\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT26Xi3LNsmE"
      },
      "source": [
        "import re \n",
        "import logging"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0D7LWMZN3Ue"
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
        "logging.root.setLevel(level=logging.INFO)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt2zp82WN8rL",
        "outputId": "79b1e62c-dfc5-4607-c5f8-1176e43c793c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZuzgecLOAyM"
      },
      "source": [
        "stop_words = stop_words + ['com', 'edu', 'subject', 'lines', 'organization', 'would', 'article', 'could']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_8SSj3mONeQ",
        "outputId": "4334333f-1d64-4ff4-f776-480e06ecffb0"
      },
      "source": [
        "dataset=api.load('text8')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-06 14:50:16,466 : INFO : Creating /root/gensim-data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-06 14:50:27,130 : INFO : text8 downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9GGwHpfOVO9"
      },
      "source": [
        "data=[d for d in dataset]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp84mONcOhxH",
        "outputId": "8e2acea8-5f0f-4bb0-de31-39255d10151c"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1701"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWmbn5OBOj1r",
        "outputId": "d43c5e41-b8a5-4cec-811e-4f831edebc9a"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUfJiLHoQ5Vl"
      },
      "source": [
        "!pip install pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wocoE9lbOmQM",
        "outputId": "21f0d3d7-a282-463c-86c1-ab2989c32f47"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHW1AU4GQH6d",
        "outputId": "755b0c38-92c6-4c46-e7b1-45bb53fe1f04"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1701"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfHBKmteRj3v"
      },
      "source": [
        "data=data[:100]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al8CY3q7RzJ9"
      },
      "source": [
        "data_processed=[]\n",
        "for line in data:\n",
        "  if line not in stop_words:\n",
        "    data_processed.append(line)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoIQfqxuSBv3",
        "outputId": "34098984-238b-42ef-fccf-12714e287828"
      },
      "source": [
        "dictionary=corpora.Dictionary(data_processed)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-06 15:08:06,167 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2021-12-06 15:08:06,830 : INFO : built Dictionary(52754 unique tokens: ['a', 'abacus', 'abilities', 'ability', 'able']...) from 100 documents (total 1000000 corpus positions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JEHQuZcSEVo",
        "outputId": "58e6caca-5bf2-4ca0-bfd7-0798d7d5ab6f"
      },
      "source": [
        "print(dictionary)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(52754 unique tokens: ['a', 'abacus', 'abilities', 'ability', 'able']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB4ge6h4SfAu"
      },
      "source": [
        "corpus=[]\n",
        "for word in data_processed:\n",
        "  corpus.append(dictionary.doc2bow(word))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs8q-2iaS7Ay",
        "outputId": "12561a2c-a126-4069-95c1-076ca64c0f8d"
      },
      "source": [
        "lda_model = LdaMulticore(corpus=corpus,\n",
        "                         id2word=dictionary,\n",
        "                         random_state=100,\n",
        "                         num_topics=7,\n",
        "                         passes=10,\n",
        "                         chunksize=1000,\n",
        "                         batch=False,\n",
        "                         alpha='asymmetric',\n",
        "                         decay=0.5,\n",
        "                         offset=64,\n",
        "                         eta=None,\n",
        "                         eval_every=0,\n",
        "                         iterations=100,\n",
        "                         gamma_threshold=0.001,\n",
        "                         per_word_topics=True)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-06 15:12:52,700 : INFO : using asymmetric alpha [0.26219156, 0.19027454, 0.14931786, 0.12287004, 0.104381524, 0.090729296, 0.080235206]\n",
            "2021-12-06 15:12:52,703 : INFO : using symmetric eta at 0.14285714285714285\n",
            "2021-12-06 15:12:52,717 : INFO : using serial LDA version on this node\n",
            "2021-12-06 15:12:52,762 : INFO : running online LDA training, 7 topics, 10 passes over the supplied corpus of 100 documents, updating every 1000 documents, evaluating every ~0 documents, iterating 100x with a convergence threshold of 0.001000\n",
            "2021-12-06 15:12:52,764 : INFO : training LDA model using 1 processes\n",
            "2021-12-06 15:12:52,790 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:12:54,985 : INFO : topic #6 (0.080): 0.018*\"the\" + 0.006*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.005*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.003*\"nine\"\n",
            "2021-12-06 15:12:54,989 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.003*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"zero\" + 0.002*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:12:54,998 : INFO : topic #2 (0.149): 0.009*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:12:55,004 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.003*\"in\" + 0.003*\"and\" + 0.003*\"of\" + 0.002*\"to\" + 0.002*\"nine\" + 0.002*\"a\" + 0.002*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:12:55,008 : INFO : topic #0 (0.262): 0.021*\"the\" + 0.011*\"one\" + 0.011*\"of\" + 0.010*\"in\" + 0.008*\"and\" + 0.007*\"nine\" + 0.006*\"to\" + 0.006*\"zero\" + 0.005*\"a\" + 0.004*\"two\"\n",
            "2021-12-06 15:12:55,011 : INFO : topic diff=0.245981, rho=0.125000\n",
            "2021-12-06 15:12:57,970 : INFO : -8.349 per-word bound, 326.0 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:12:57,972 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:00,079 : INFO : topic #6 (0.080): 0.018*\"the\" + 0.006*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.005*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.003*\"nine\"\n",
            "2021-12-06 15:13:00,090 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.003*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"zero\" + 0.002*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:00,093 : INFO : topic #2 (0.149): 0.009*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:00,097 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.003*\"in\" + 0.003*\"and\" + 0.003*\"of\" + 0.002*\"to\" + 0.002*\"nine\" + 0.002*\"a\" + 0.002*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:00,101 : INFO : topic #0 (0.262): 0.026*\"the\" + 0.019*\"one\" + 0.014*\"of\" + 0.012*\"nine\" + 0.012*\"in\" + 0.010*\"and\" + 0.008*\"zero\" + 0.007*\"to\" + 0.007*\"two\" + 0.006*\"eight\"\n",
            "2021-12-06 15:13:00,104 : INFO : topic diff=0.161567, rho=0.123939\n",
            "2021-12-06 15:13:02,265 : INFO : -7.881 per-word bound, 235.7 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:02,272 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:03,606 : INFO : topic #6 (0.080): 0.017*\"the\" + 0.006*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.005*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.003*\"nine\"\n",
            "2021-12-06 15:13:03,614 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.003*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:03,620 : INFO : topic #2 (0.149): 0.009*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:03,627 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.003*\"in\" + 0.003*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.002*\"nine\" + 0.002*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:03,631 : INFO : topic #0 (0.262): 0.026*\"the\" + 0.022*\"one\" + 0.014*\"nine\" + 0.014*\"of\" + 0.012*\"in\" + 0.010*\"and\" + 0.009*\"zero\" + 0.008*\"two\" + 0.007*\"to\" + 0.007*\"eight\"\n",
            "2021-12-06 15:13:03,634 : INFO : topic diff=0.110470, rho=0.122998\n",
            "2021-12-06 15:13:05,949 : INFO : -7.777 per-word bound, 219.3 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:05,952 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:07,208 : INFO : topic #6 (0.080): 0.017*\"the\" + 0.005*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.005*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.003*\"nine\"\n",
            "2021-12-06 15:13:07,214 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.003*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:07,219 : INFO : topic #2 (0.149): 0.009*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:07,223 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.003*\"in\" + 0.003*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:07,225 : INFO : topic #0 (0.262): 0.025*\"the\" + 0.025*\"one\" + 0.016*\"nine\" + 0.014*\"of\" + 0.012*\"in\" + 0.010*\"and\" + 0.009*\"zero\" + 0.009*\"two\" + 0.008*\"eight\" + 0.007*\"to\"\n",
            "2021-12-06 15:13:07,231 : INFO : topic diff=0.100261, rho=0.122078\n",
            "2021-12-06 15:13:09,384 : INFO : -7.727 per-word bound, 211.9 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:09,391 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:10,550 : INFO : topic #6 (0.080): 0.017*\"the\" + 0.005*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.005*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.003*\"nine\"\n",
            "2021-12-06 15:13:10,557 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.003*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:10,564 : INFO : topic #2 (0.149): 0.009*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:10,570 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:10,575 : INFO : topic #0 (0.262): 0.028*\"one\" + 0.025*\"the\" + 0.018*\"nine\" + 0.014*\"of\" + 0.012*\"in\" + 0.010*\"zero\" + 0.010*\"and\" + 0.009*\"two\" + 0.009*\"eight\" + 0.007*\"five\"\n",
            "2021-12-06 15:13:10,580 : INFO : topic diff=0.100194, rho=0.121179\n",
            "2021-12-06 15:13:12,683 : INFO : -7.693 per-word bound, 207.0 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:12,686 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:13,888 : INFO : topic #6 (0.080): 0.016*\"the\" + 0.005*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.002*\"nine\"\n",
            "2021-12-06 15:13:13,891 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.002*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:13,895 : INFO : topic #2 (0.149): 0.008*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:13,900 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:13,920 : INFO : topic #0 (0.262): 0.031*\"one\" + 0.025*\"the\" + 0.021*\"nine\" + 0.014*\"of\" + 0.012*\"in\" + 0.011*\"zero\" + 0.010*\"eight\" + 0.010*\"two\" + 0.010*\"and\" + 0.008*\"five\"\n",
            "2021-12-06 15:13:13,924 : INFO : topic diff=0.103726, rho=0.120299\n",
            "2021-12-06 15:13:16,093 : INFO : -7.666 per-word bound, 203.2 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:16,095 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:17,339 : INFO : topic #6 (0.080): 0.016*\"the\" + 0.005*\"of\" + 0.005*\"and\" + 0.005*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.002*\"nine\"\n",
            "2021-12-06 15:13:17,341 : INFO : topic #5 (0.091): 0.004*\"one\" + 0.003*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.001*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:17,347 : INFO : topic #2 (0.149): 0.008*\"the\" + 0.007*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:17,351 : INFO : topic #1 (0.190): 0.007*\"the\" + 0.003*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:17,356 : INFO : topic #0 (0.262): 0.035*\"one\" + 0.025*\"the\" + 0.023*\"nine\" + 0.014*\"of\" + 0.012*\"in\" + 0.011*\"zero\" + 0.011*\"eight\" + 0.011*\"two\" + 0.010*\"and\" + 0.009*\"five\"\n",
            "2021-12-06 15:13:17,360 : INFO : topic diff=0.108760, rho=0.119438\n",
            "2021-12-06 15:13:19,449 : INFO : -7.643 per-word bound, 199.9 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:19,456 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:20,614 : INFO : topic #6 (0.080): 0.015*\"the\" + 0.005*\"of\" + 0.005*\"and\" + 0.004*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.002*\"nine\"\n",
            "2021-12-06 15:13:20,617 : INFO : topic #5 (0.091): 0.003*\"one\" + 0.003*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.002*\"and\" + 0.001*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:20,623 : INFO : topic #2 (0.149): 0.008*\"the\" + 0.006*\"of\" + 0.005*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.003*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:20,627 : INFO : topic #1 (0.190): 0.006*\"the\" + 0.003*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:20,631 : INFO : topic #0 (0.262): 0.039*\"one\" + 0.025*\"nine\" + 0.025*\"the\" + 0.015*\"of\" + 0.012*\"eight\" + 0.012*\"zero\" + 0.012*\"two\" + 0.011*\"in\" + 0.010*\"and\" + 0.009*\"five\"\n",
            "2021-12-06 15:13:20,635 : INFO : topic diff=0.114449, rho=0.118595\n",
            "2021-12-06 15:13:22,690 : INFO : -7.622 per-word bound, 197.0 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:22,693 : INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:23,868 : INFO : topic #6 (0.080): 0.015*\"the\" + 0.005*\"of\" + 0.005*\"and\" + 0.004*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.003*\"is\" + 0.002*\"nine\"\n",
            "2021-12-06 15:13:23,877 : INFO : topic #5 (0.091): 0.003*\"one\" + 0.002*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.001*\"and\" + 0.001*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:23,882 : INFO : topic #2 (0.149): 0.008*\"the\" + 0.006*\"of\" + 0.004*\"and\" + 0.003*\"in\" + 0.003*\"one\" + 0.003*\"to\" + 0.002*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:23,889 : INFO : topic #1 (0.190): 0.006*\"the\" + 0.003*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:23,892 : INFO : topic #0 (0.262): 0.042*\"one\" + 0.028*\"nine\" + 0.025*\"the\" + 0.015*\"of\" + 0.014*\"eight\" + 0.013*\"zero\" + 0.012*\"two\" + 0.011*\"in\" + 0.010*\"five\" + 0.010*\"and\"\n",
            "2021-12-06 15:13:23,895 : INFO : topic diff=0.120292, rho=0.117769\n",
            "2021-12-06 15:13:25,941 : INFO : -7.603 per-word bound, 194.5 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n",
            "2021-12-06 15:13:25,943 : INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #100/100, outstanding queue size 1\n",
            "2021-12-06 15:13:27,065 : INFO : topic #6 (0.080): 0.014*\"the\" + 0.005*\"of\" + 0.004*\"and\" + 0.004*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.002*\"is\" + 0.002*\"nine\"\n",
            "2021-12-06 15:13:27,069 : INFO : topic #5 (0.091): 0.003*\"one\" + 0.002*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.001*\"and\" + 0.001*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:13:27,074 : INFO : topic #2 (0.149): 0.007*\"the\" + 0.006*\"of\" + 0.004*\"and\" + 0.003*\"in\" + 0.002*\"one\" + 0.002*\"to\" + 0.002*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:13:27,078 : INFO : topic #1 (0.190): 0.006*\"the\" + 0.002*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:13:27,082 : INFO : topic #0 (0.262): 0.046*\"one\" + 0.030*\"nine\" + 0.025*\"the\" + 0.015*\"of\" + 0.015*\"eight\" + 0.014*\"zero\" + 0.013*\"two\" + 0.011*\"in\" + 0.011*\"five\" + 0.010*\"seven\"\n",
            "2021-12-06 15:13:27,087 : INFO : topic diff=0.125943, rho=0.116961\n",
            "2021-12-06 15:13:29,124 : INFO : -7.586 per-word bound, 192.2 perplexity estimate based on a held-out corpus of 100 documents with 1000000 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBZxETTzS_fC",
        "outputId": "da362add-318b-4dc2-ea84-8855d0d58270"
      },
      "source": [
        "lda_model.save('lda_model.model')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-06 15:14:12,258 : INFO : saving LdaState object under lda_model.model.state, separately None\n",
            "2021-12-06 15:14:12,275 : INFO : saved lda_model.model.state\n",
            "2021-12-06 15:14:12,301 : INFO : saving LdaMulticore object under lda_model.model, separately ['expElogbeta', 'sstats']\n",
            "2021-12-06 15:14:12,302 : INFO : storing np array 'expElogbeta' to lda_model.model.expElogbeta.npy\n",
            "2021-12-06 15:14:12,308 : INFO : not storing attribute state\n",
            "2021-12-06 15:14:12,312 : INFO : not storing attribute id2word\n",
            "2021-12-06 15:14:12,314 : INFO : not storing attribute dispatcher\n",
            "2021-12-06 15:14:12,324 : INFO : saved lda_model.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRn-gaRuTzxB",
        "outputId": "a2960de9-11a8-4fd7-daa5-f89d09081b83"
      },
      "source": [
        "lda_model.print_topics(-1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-06 15:14:32,018 : INFO : topic #0 (0.262): 0.046*\"one\" + 0.030*\"nine\" + 0.025*\"the\" + 0.015*\"of\" + 0.015*\"eight\" + 0.014*\"zero\" + 0.013*\"two\" + 0.011*\"in\" + 0.011*\"five\" + 0.010*\"seven\"\n",
            "2021-12-06 15:14:32,023 : INFO : topic #1 (0.190): 0.006*\"the\" + 0.002*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"\n",
            "2021-12-06 15:14:32,026 : INFO : topic #2 (0.149): 0.007*\"the\" + 0.006*\"of\" + 0.004*\"and\" + 0.003*\"in\" + 0.002*\"one\" + 0.002*\"to\" + 0.002*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"\n",
            "2021-12-06 15:14:32,029 : INFO : topic #3 (0.123): 0.062*\"the\" + 0.036*\"of\" + 0.025*\"and\" + 0.022*\"in\" + 0.021*\"one\" + 0.019*\"a\" + 0.018*\"to\" + 0.013*\"zero\" + 0.012*\"nine\" + 0.011*\"is\"\n",
            "2021-12-06 15:14:32,032 : INFO : topic #4 (0.104): 0.016*\"the\" + 0.012*\"of\" + 0.006*\"one\" + 0.005*\"in\" + 0.005*\"a\" + 0.004*\"and\" + 0.004*\"zero\" + 0.003*\"to\" + 0.003*\"two\" + 0.003*\"is\"\n",
            "2021-12-06 15:14:32,035 : INFO : topic #5 (0.091): 0.003*\"one\" + 0.002*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.001*\"and\" + 0.001*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"\n",
            "2021-12-06 15:14:32,038 : INFO : topic #6 (0.080): 0.014*\"the\" + 0.005*\"of\" + 0.004*\"and\" + 0.004*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.002*\"is\" + 0.002*\"nine\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.046*\"one\" + 0.030*\"nine\" + 0.025*\"the\" + 0.015*\"of\" + 0.015*\"eight\" + 0.014*\"zero\" + 0.013*\"two\" + 0.011*\"in\" + 0.011*\"five\" + 0.010*\"seven\"'),\n",
              " (1,\n",
              "  '0.006*\"the\" + 0.002*\"one\" + 0.002*\"in\" + 0.002*\"and\" + 0.002*\"of\" + 0.002*\"to\" + 0.001*\"nine\" + 0.001*\"a\" + 0.001*\"zero\" + 0.001*\"two\"'),\n",
              " (2,\n",
              "  '0.007*\"the\" + 0.006*\"of\" + 0.004*\"and\" + 0.003*\"in\" + 0.002*\"one\" + 0.002*\"to\" + 0.002*\"a\" + 0.002*\"is\" + 0.002*\"two\" + 0.002*\"zero\"'),\n",
              " (3,\n",
              "  '0.062*\"the\" + 0.036*\"of\" + 0.025*\"and\" + 0.022*\"in\" + 0.021*\"one\" + 0.019*\"a\" + 0.018*\"to\" + 0.013*\"zero\" + 0.012*\"nine\" + 0.011*\"is\"'),\n",
              " (4,\n",
              "  '0.016*\"the\" + 0.012*\"of\" + 0.006*\"one\" + 0.005*\"in\" + 0.005*\"a\" + 0.004*\"and\" + 0.004*\"zero\" + 0.003*\"to\" + 0.003*\"two\" + 0.003*\"is\"'),\n",
              " (5,\n",
              "  '0.003*\"one\" + 0.002*\"of\" + 0.002*\"nine\" + 0.002*\"the\" + 0.001*\"and\" + 0.001*\"zero\" + 0.001*\"eight\" + 0.001*\"two\" + 0.001*\"to\" + 0.001*\"seven\"'),\n",
              " (6,\n",
              "  '0.014*\"the\" + 0.005*\"of\" + 0.004*\"and\" + 0.004*\"to\" + 0.004*\"a\" + 0.004*\"in\" + 0.004*\"one\" + 0.003*\"zero\" + 0.002*\"is\" + 0.002*\"nine\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4tDzJYZT4lt",
        "outputId": "45e29867-0370-486e-e91a-1646c1ac6075"
      },
      "source": [
        "for c in lda_model[corpus[5:8]]:\n",
        "    print(\"Document Topics      : \", c[0])      # [(Topics, Perc Contrib)]\n",
        "    print(\"Word id, Topics      : \", c[1][:3])  # [(Word id, [Topics])]\n",
        "    print(\"Phi Values (word id) : \", c[2][:2])  # [(Word id, [(Topic, Phi Value)])]\n",
        "    print(\"Word, Topics         : \", [(dictionary[wd], topic) for wd, topic in c[1][:2]])   # [(Word, [Topics])]\n",
        "    print(\"Phi Values (word)    : \", [(dictionary[wd], topic) for wd, topic in c[2][:2]])  # [(Word, [(Topic, Phi Value)])]\n",
        "    print(\"------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Topics      :  [(3, 0.99991065)]\n",
            "Word id, Topics      :  [(0, [3]), (3, [3]), (8, [3])]\n",
            "Phi Values (word id) :  [(0, [(3, 158.9999)]), (3, [(3, 2.9999986)])]\n",
            "Word, Topics         :  [('a', [3]), ('ability', [3])]\n",
            "Phi Values (word)    :  [('a', [(3, 158.9999)]), ('ability', [(3, 2.9999986)])]\n",
            "------------------------------------------------------\n",
            "\n",
            "Document Topics      :  [(3, 0.99991095)]\n",
            "Word id, Topics      :  [(0, [3]), (3, [3]), (8, [3])]\n",
            "Phi Values (word id) :  [(0, [(3, 198.99988)]), (3, [(3, 5.999997)])]\n",
            "Word, Topics         :  [('a', [3]), ('ability', [3])]\n",
            "Phi Values (word)    :  [('a', [(3, 198.99988)]), ('ability', [(3, 5.999997)])]\n",
            "------------------------------------------------------\n",
            "\n",
            "Document Topics      :  [(3, 0.99991125)]\n",
            "Word id, Topics      :  [(0, [3]), (4, [3]), (8, [3])]\n",
            "Phi Values (word id) :  [(0, [(3, 142.99991)]), (4, [(3, 0.9999994)])]\n",
            "Word, Topics         :  [('a', [3]), ('able', [3])]\n",
            "Phi Values (word)    :  [('a', [(3, 142.99991)]), ('able', [(3, 0.9999994)])]\n",
            "------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7swQBjhXUOvf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}